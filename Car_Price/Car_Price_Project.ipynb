{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ac09a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558bc24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the data\n",
    "data = pd.read_csv('C:\\\\Users\\\\KMS9BAN\\\\Desktop\\\\fwdprojectstobesharedwithd49d50\\\\cars_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaf7835",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Step 2: Split the data into training and test sets\n",
    "X = data.drop('price', axis=1)\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e6041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Handle missing values\n",
    "\n",
    "# For numeric columns with missing values, you can use imputation techniques like mean or median\n",
    "X_train.loc[:, 'normalized-losses'] = X_train['normalized-losses'].replace('?', np.nan).astype(float)\n",
    "\n",
    "# For categorical columns with missing values, you can either impute with the most frequent value or drop the rows/columns\n",
    "X_train['num-of-doors'].fillna(X_train['num-of-doors'].mode()[0], inplace=True)\n",
    "\n",
    "print(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95167e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables using one-hot encoding\n",
    "encoder = OneHotEncoder()\n",
    "X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train[['make', 'fuel-type', 'aspiration', 'body-style', 'drive-wheels', 'engine-location', 'engine-type', 'num-of-cylinders', 'fuel-system']]).toarray(),\n",
    "                               columns=encoder.get_feature_names(['make', 'fuel-type', 'aspiration', 'body-style', 'drive-wheels', 'engine-location', 'engine-type', 'num-of-cylinders', 'fuel-system']))\n",
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f06c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the encoded features with the numerical features\n",
    "X_train_preprocessed = pd.concat([X_train_encoded, X_train.select_dtypes(include=['float64', 'int64'])], axis=1)\n",
    "X_train_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40636ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Apply different machine learning techniques\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ccf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the mismatched rows\n",
    "mismatched_rows = set(X_train_preprocessed.index) - set(y_train.index)\n",
    "\n",
    "# Drop the mismatched rows from X_train_preprocessed and y_train\n",
    "X_train_preprocessed.drop(mismatched_rows, inplace=True)\n",
    "y_train = y_train.loc[X_train_preprocessed.index]\n",
    "\n",
    "# Verify the shapes of the arrays\n",
    "print(\"X_train_preprocessed shape:\", X_train_preprocessed.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in X_train_preprocessed\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_preprocessed = imputer.fit_transform(X_train_preprocessed)\n",
    "\n",
    "# Create a new DataFrame from X_train_preprocessed\n",
    "X_train_preprocessed = pd.DataFrame(X_train_preprocessed)\n",
    "\n",
    "# Identify the mismatched rows\n",
    "mismatched_indices = set(X_train_preprocessed.index) - set(np.arange(len(y_train)))\n",
    "\n",
    "# Drop the mismatched rows from X_train_preprocessed\n",
    "X_train_preprocessed.drop(list(mismatched_indices), inplace=True)\n",
    "\n",
    "# Remove the mismatched rows from y_train\n",
    "y_train = np.delete(y_train, list(mismatched_indices))\n",
    "\n",
    "# Handle missing values in X_train_preprocessed again after dropping rows\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_preprocessed = imputer.fit_transform(X_train_preprocessed)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_preprocessed = scaler.fit_transform(X_train_preprocessed)\n",
    "\n",
    "# Check the number of samples in X_train_preprocessed and y_train\n",
    "if len(X_train_preprocessed) != len(y_train):\n",
    "    raise ValueError(\"Inconsistent number of samples between X_train_preprocessed and y_train.\")\n",
    "\n",
    "# Create the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Build the final model\n",
    "model.fit(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the test data in a similar way as the training data\n",
    "X_test['normalized-losses'].fillna(X_train['normalized-losses'].mean(), inplace=True)\n",
    "X_test['num-of-doors'].fillna(X_train['num-of-doors'].mode()[0], inplace=True)\n",
    "\n",
    "# Handle unknown categories in the encoder\n",
    "encoder.set_params(handle_unknown='ignore')\n",
    "\n",
    "# Encode the categorical features in X_test\n",
    "X_test_encoded = pd.DataFrame(encoder.transform(X_test[['make', 'fuel-type', 'aspiration', 'body-style', 'drive-wheels', 'engine-location', 'engine-type', 'num-of-cylinders', 'fuel-system']]).toarray(),\n",
    "                              columns=encoder.get_feature_names(['make', 'fuel-type', 'aspiration', 'body-style', 'drive-wheels', 'engine-location', 'engine-type', 'num-of-cylinders', 'fuel-system']))\n",
    "\n",
    "# Create a copy of the numeric features in X_test\n",
    "X_test_numeric = X_test.select_dtypes(include=['float64', 'int64']).copy()\n",
    "\n",
    "# Concatenate the encoded features with the numeric features\n",
    "X_test_preprocessed = pd.concat([X_test_encoded, X_test_numeric], axis=1)\n",
    "\n",
    "# Handle missing values in X_test_preprocessed\n",
    "X_test_preprocessed['num-of-cylinders_three'] = 0  # Add missing column with zeros\n",
    "X_test_preprocessed = imputer.transform(X_test_preprocessed)\n",
    "\n",
    "# Standardize the features in X_test_preprocessed\n",
    "X_test_preprocessed = scaler.transform(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e18ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_preprocessed)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2886c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the test data in a similar way as the training data\n",
    "X_test['normalized-losses'].fillna(X_train['normalized-losses'].mean(), inplace=True)\n",
    "X_test['num-of-doors'].fillna(X_train['num-of-doors'].mode()[0], inplace=True)\n",
    "\n",
    "# Handle unknown categories in the encoder\n",
    "encoder.set_params(handle_unknown='ignore')\n",
    "\n",
    "X_test_encoded = pd.DataFrame(encoder.transform(X_test[['make', 'fuel-type', 'aspiration', 'body-style', 'drive-wheels', 'engine-location', 'engine-type', 'num-of-cylinders', 'fuel-system']]).toarray(),\n",
    "                              columns=encoder.get_feature_names(['make', 'fuel-type', 'aspiration', 'body-style', 'drive-wheels', 'engine-location', 'engine-type', 'num-of-cylinders', 'fuel-system']))\n",
    "\n",
    "# Concatenate the encoded features with the numeric features\n",
    "X_test_preprocessed = pd.concat([X_test_encoded, X_test.select_dtypes(include=['float64', 'int64']).copy()], axis=1)\n",
    "\n",
    "# Handle missing values in X_test_preprocessed\n",
    "X_test_preprocessed = pd.DataFrame(imputer.transform(X_test_preprocessed), columns=X_test_preprocessed.columns)\n",
    "\n",
    "# Standardize the features in X_test_preprocessed\n",
    "X_test_preprocessed = pd.DataFrame(scaler.transform(X_test_preprocessed), columns=X_test_preprocessed.columns)\n",
    "\n",
    "# Ensure the number of samples in X_test_preprocessed and y_test is consistent\n",
    "if len(X_test_preprocessed) != len(y_test):\n",
    "    raise ValueError(\"Inconsistent number of samples between X_test_preprocessed and y_test.\")\n",
    "\n",
    "# Calculate predictions\n",
    "y_pred = model.predict(X_test_preprocessed)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0da0155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
